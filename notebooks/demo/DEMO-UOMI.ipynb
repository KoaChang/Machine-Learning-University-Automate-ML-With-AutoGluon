{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-image: linear-gradient(145deg, rgba(35, 47, 62, 1) 0%, rgba(0, 49, 129, 1) 40%, rgba(32, 116, 213, 1) 60%, rgba(244, 110, 197, 1) 85%, rgba(255, 173, 151, 1) 100%); padding: 1rem 2rem;\n",
    "\"><img src=\"https://cdn-prod.mlu.aws.dev/static/amazon_apollo_django_setup_staging/da021f332105bfea6edc2b02f78330ab1e750dfb01896a80b9676a49743759a4/img/mlu_logo.png\" class=\"logo\" alt=\"MLU Logo\"></div>\n",
    "    \n",
    "# <a name=\"0\">Automated Machine Learning (AutoML) with AutoGluon - Demo</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[__AutoGluon__](https://auto.gluon.ai/stable/index.html#) automates machine learning tasks and enables you to easily achieve strong predictive performance in your applications with just a few lines of code. \n",
    "\n",
    "This notebook shows how to use AutoGluon Tabular to solve a __multiclass classification task__. The metric we use to evaluate the performance of the model is accuracy.\n",
    "\n",
    "1. <a href=\"#1\">Business Problem and ML Problem Description</a>\n",
    "2. <a href=\"#2\">Installing AutoGluon</a>\n",
    "3. <a href=\"#3\">Loading the Data</a>\n",
    "4. <a href=\"#4\">Sampling Data</a>\n",
    "5. <a href=\"#5\">Model Training with AutoGluon (smaller train dataset)</a>\n",
    "6. <a href=\"#6\">AutoGluon Training Results</a>\n",
    "7. <a href=\"#7\">Model Prediction with AutoGluon</a>\n",
    "8. <a href=\"#8\">Re-Train (with full train data) and predict again</a>\n",
    "9. <a href=\"#9\">Before You Go (clean up model artifacts)</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. <a name=\"1\">Business Problem and ML Problem Description</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "__Business Problem:__ Products from the Amazon Product Catalog cannot be listed for sale because they are missing some relevant information, the Unit Of Measure (count, volume, weight). \n",
    "\n",
    "__ML Problem Description:__ Predict the Unit Of Measure (count, volume, weight) Identification (UOMI) for a product from the Amazon Product Catalog. This is a __multiclass classification__ task (3 distinct classes: count, volume, weight). The dataset for this ML problem has 33 features columns and 1 label column. Below some examples of the features that are included in the dataset:\n",
    "\n",
    "\n",
    "| Feature | Description |\n",
    "| :---        |    :----  |\n",
    "| marketplace_id | Marketplace ID.|\n",
    "| product_type   | Type of product.  |\n",
    "| item_name | Short item description. |\n",
    "| product_description   | Long item description.  |\n",
    "| bullet_point | Bullet point item description. |\n",
    "| brand   | Brand name.  |\n",
    "| manufacturer | Manufacturer name. |\n",
    "| ...   | ...  |\n",
    "| list_price_value_with_tax   | Price of item including tax.  |\n",
    "| imgID | ID for image of product. |\n",
    "| ID   | Product identifier.  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 2. <a name=\"2\">Installing AutoGluon</a>\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -q autogluon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the libraries needed to work with our tabular dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load in AutoGluon\n",
    "from autogluon.tabular import TabularPredictor, TabularDataset\n",
    "\n",
    "# Load in libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 3. <a name=\"3\">Loading the Data</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Let's load the datasets and look at a few data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load train and test data splits from csv files into TabularDatasets\n",
    "train = TabularDataset(\"../../data/uomi-train.csv\")\n",
    "test = TabularDataset(\"../../data/uomi-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 28305\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>marketplace_id</th>\n",
       "      <th>label</th>\n",
       "      <th>product_type</th>\n",
       "      <th>item_name</th>\n",
       "      <th>product_description</th>\n",
       "      <th>bullet_point</th>\n",
       "      <th>brand</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>part_number</th>\n",
       "      <th>...</th>\n",
       "      <th>item_dimensions_height</th>\n",
       "      <th>item_dimensions_width</th>\n",
       "      <th>item_dimensions_length</th>\n",
       "      <th>normalized_item_weight</th>\n",
       "      <th>normalized_item_package_weight</th>\n",
       "      <th>list_price_currency</th>\n",
       "      <th>list_price_value</th>\n",
       "      <th>list_price_value_with_tax</th>\n",
       "      <th>imgID</th>\n",
       "      <th>ID_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1633</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>JELL-O Play Ocean Build + Eat Kit, 6 oz Box</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One 6 oz. JELL-O Play Ocean Build + Eat Kit</td>\n",
       "      <td>Jell-O Play</td>\n",
       "      <td>Jell-o</td>\n",
       "      <td>4300008150</td>\n",
       "      <td>...</td>\n",
       "      <td>2.625</td>\n",
       "      <td>6.625</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.500449</td>\n",
       "      <td>USD</td>\n",
       "      <td>3.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51sislDjTYL</td>\n",
       "      <td>9cd726a519754b6bad27be39bc95cac6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18103</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>Crystal Light Pure Variety Pack includes- Rasp...</td>\n",
       "      <td>With no artificial sweeteners, flavors or pres...</td>\n",
       "      <td>Customer Will Receive 6 Boxes Total - 1 Raspbe...</td>\n",
       "      <td>Crystal Light</td>\n",
       "      <td>Crystal Light</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.599657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41MsGCednqL</td>\n",
       "      <td>44a997b7ff9f4d2ebd1615ac5f3861ff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  marketplace_id  label product_type  \\\n",
       "0   1633               1      1      GROCERY   \n",
       "1  18103               1      2      GROCERY   \n",
       "\n",
       "                                           item_name  \\\n",
       "0        JELL-O Play Ocean Build + Eat Kit, 6 oz Box   \n",
       "1  Crystal Light Pure Variety Pack includes- Rasp...   \n",
       "\n",
       "                                 product_description  \\\n",
       "0                                                NaN   \n",
       "1  With no artificial sweeteners, flavors or pres...   \n",
       "\n",
       "                                        bullet_point          brand  \\\n",
       "0        One 6 oz. JELL-O Play Ocean Build + Eat Kit    Jell-O Play   \n",
       "1  Customer Will Receive 6 Boxes Total - 1 Raspbe...  Crystal Light   \n",
       "\n",
       "    manufacturer part_number  ... item_dimensions_height  \\\n",
       "0         Jell-o  4300008150  ...                  2.625   \n",
       "1  Crystal Light         NaN  ...                    NaN   \n",
       "\n",
       "  item_dimensions_width item_dimensions_length normalized_item_weight  \\\n",
       "0                 6.625                    8.5               0.023438   \n",
       "1                   NaN                    NaN                    NaN   \n",
       "\n",
       "  normalized_item_package_weight list_price_currency list_price_value  \\\n",
       "0                       0.500449                 USD             3.99   \n",
       "1                       0.599657                 NaN              NaN   \n",
       "\n",
       "  list_price_value_with_tax        imgID                              ID_0  \n",
       "0                       NaN  51sislDjTYL  9cd726a519754b6bad27be39bc95cac6  \n",
       "1                       NaN  41MsGCednqL  44a997b7ff9f4d2ebd1615ac5f3861ff  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print size of train set\n",
    "print(f\"Size of training set: {len(train)}\")\n",
    "\n",
    "# Show the first rows of train data\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 4. <a name=\"4\">Sampling Data</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "It is good practice to grab a small sample dataset to quickly run AutoGluon before using the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take a sample of 1000 datapoints for a quick test\n",
    "train_sample_small = train.sample(n=1000, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 5. <a name=\"5\">Model Training with AutoGluon</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "\n",
    "We can train a model using AutoGluon with only a single line of code.  All we need to do is tell AutoGluon what column from the dataset we want to predict, and what the train dataset is.\n",
    "\n",
    "For fast experimentation, we use only the small sample from our train dataset, containing 1000 data points.\n",
    "\n",
    "__NOTE__: Training on this smaller dataset might still take approx. 3-4 minutes!\n",
    "\n",
    "__AUTOGLUON FIT OUTPUT__: Running `.fit` to train a model with AutoGluon triggers the output of multiple details about the training process. See the output of the cell below. AutoGluon prints information regarding: \n",
    "- the path where trained models are stored. If no path is specified, AutoGluon uses a default value. This is not a problem.\n",
    "- specified presets for the training. If no presets are specified, AutoGluon issues a warning and a recommendation. It is not a problem to train without presets, although improved performance is expected using the recommended presets.\n",
    "- system info including software and OS versions, hardware specs\n",
    "- size of training data\n",
    "- type of problem as inferred by AutoGluon\n",
    "- data preprocessing operations\n",
    "- details of all ML algorithms that are being trained, including training and validation metrics\n",
    "- model training completion, total runtime, and best model\n",
    "\n",
    "Pay attention to the output below to identify all pieces of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240106_002857\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240106_002857\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Sep 6 21:15:41 UTC 2023\n",
      "CPU Count:          4\n",
      "Memory Avail:       12.58 GB / 15.32 GB (82.1%)\n",
      "Disk Space Avail:   45.16 GB / 49.04 GB (92.1%)\n",
      "===================================================\n",
      "Train Data Rows:    1000\n",
      "Train Data Columns: 33\n",
      "Label Column:       label\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [2, 0, 1]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    12883.42 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.28 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['item_name', 'product_description', 'bullet_point', 'generic_keyword', 'style']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 629\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['marketplace_id', 'list_price_value_with_tax']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 2): ['imgID', 'ID_0']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 2 | ['imgID', 'ID_0']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        :  9 | ['number_of_items', 'case_pack_quantity', 'item_package_quantity', 'item_dimensions_height', 'item_dimensions_width', ...]\n",
      "\t\t('int', [])          :  1 | ['ID']\n",
      "\t\t('object', [])       : 14 | ['product_type', 'brand', 'manufacturer', 'part_number', 'model_number', ...]\n",
      "\t\t('object', ['text']) :  5 | ['item_name', 'product_description', 'bullet_point', 'generic_keyword', 'style']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :  13 | ['product_type', 'brand', 'manufacturer', 'part_number', 'model_number', ...]\n",
      "\t\t('category', ['text_as_category'])  :   4 | ['product_description', 'bullet_point', 'generic_keyword', 'style']\n",
      "\t\t('float', [])                       :   9 | ['number_of_items', 'case_pack_quantity', 'item_package_quantity', 'item_dimensions_height', 'item_dimensions_width', ...]\n",
      "\t\t('int', [])                         :   1 | ['ID']\n",
      "\t\t('int', ['binned', 'text_special']) :  94 | ['item_name.char_count', 'item_name.word_count', 'item_name.capital_ratio', 'item_name.lower_ratio', 'item_name.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :   1 | ['list_price_currency']\n",
      "\t\t('int', ['text_ngram'])             : 629 | ['__nlp__.10', '__nlp__.100', '__nlp__.12', '__nlp__.15', '__nlp__.16', ...]\n",
      "\t12.9s = Fit runtime\n",
      "\t29 features in original data used to generate 751 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.39 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 12.98s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 800, Val Rows: 200\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.58\t = Validation score   (accuracy)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.61\t = Validation score   (accuracy)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "\t0.745\t = Validation score   (accuracy)\n",
      "\t7.59s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.755\t = Validation score   (accuracy)\n",
      "\t6.28s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.78\t = Validation score   (accuracy)\n",
      "\t6.15s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.735\t = Validation score   (accuracy)\n",
      "\t2.0s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.725\t = Validation score   (accuracy)\n",
      "\t1.59s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.82\t = Validation score   (accuracy)\n",
      "\t46.33s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.745\t = Validation score   (accuracy)\n",
      "\t1.39s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.73\t = Validation score   (accuracy)\n",
      "\t1.53s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.765\t = Validation score   (accuracy)\n",
      "\t5.3s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.75\t = Validation score   (accuracy)\n",
      "\t4.19s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.76\t = Validation score   (accuracy)\n",
      "\t10.86s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'CatBoost': 0.909, 'ExtraTreesEntr': 0.091}\n",
      "\t0.825\t = Validation score   (accuracy)\n",
      "\t1.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 109.57s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240106_002857\")\n"
     ]
    }
   ],
   "source": [
    "# We specify train and validation data for the model training\n",
    "first_predictor = TabularPredictor(label=\"label\").fit(\n",
    "    train_data=train_sample_small\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 6. <a name=\"6\">AutoGluon Training Results</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Now let's take a look at all the training information AutoGluon provides via its __leaderboard function__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.825</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.209271</td>\n",
       "      <td>49.011800</td>\n",
       "      <td>0.001021</td>\n",
       "      <td>1.151814</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.820</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.070311</td>\n",
       "      <td>46.333023</td>\n",
       "      <td>0.070311</td>\n",
       "      <td>46.333023</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.780</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.015724</td>\n",
       "      <td>6.151672</td>\n",
       "      <td>0.015724</td>\n",
       "      <td>6.151672</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.765</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.018853</td>\n",
       "      <td>5.295700</td>\n",
       "      <td>0.018853</td>\n",
       "      <td>5.295700</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.760</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.033105</td>\n",
       "      <td>10.858981</td>\n",
       "      <td>0.033105</td>\n",
       "      <td>10.858981</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.755</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.048410</td>\n",
       "      <td>6.276760</td>\n",
       "      <td>0.048410</td>\n",
       "      <td>6.276760</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.750</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.077085</td>\n",
       "      <td>4.193133</td>\n",
       "      <td>0.077085</td>\n",
       "      <td>4.193133</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.745</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.050142</td>\n",
       "      <td>7.587986</td>\n",
       "      <td>0.050142</td>\n",
       "      <td>7.587986</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.745</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.117585</td>\n",
       "      <td>1.386432</td>\n",
       "      <td>0.117585</td>\n",
       "      <td>1.386432</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.735</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.100514</td>\n",
       "      <td>2.002491</td>\n",
       "      <td>0.100514</td>\n",
       "      <td>2.002491</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.730</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.137938</td>\n",
       "      <td>1.526963</td>\n",
       "      <td>0.137938</td>\n",
       "      <td>1.526963</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.725</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.095917</td>\n",
       "      <td>1.590998</td>\n",
       "      <td>0.095917</td>\n",
       "      <td>1.590998</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.610</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>0.112142</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>0.112142</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.580</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.170330</td>\n",
       "      <td>0.232837</td>\n",
       "      <td>0.170330</td>\n",
       "      <td>0.232837</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_val eval_metric  pred_time_val   fit_time  \\\n",
       "0   WeightedEnsemble_L2      0.825    accuracy       0.209271  49.011800   \n",
       "1              CatBoost      0.820    accuracy       0.070311  46.333023   \n",
       "2              LightGBM      0.780    accuracy       0.015724   6.151672   \n",
       "3               XGBoost      0.765    accuracy       0.018853   5.295700   \n",
       "4         LightGBMLarge      0.760    accuracy       0.033105  10.858981   \n",
       "5            LightGBMXT      0.755    accuracy       0.048410   6.276760   \n",
       "6        NeuralNetTorch      0.750    accuracy       0.077085   4.193133   \n",
       "7       NeuralNetFastAI      0.745    accuracy       0.050142   7.587986   \n",
       "8        ExtraTreesGini      0.745    accuracy       0.117585   1.386432   \n",
       "9      RandomForestGini      0.735    accuracy       0.100514   2.002491   \n",
       "10       ExtraTreesEntr      0.730    accuracy       0.137938   1.526963   \n",
       "11     RandomForestEntr      0.725    accuracy       0.095917   1.590998   \n",
       "12       KNeighborsDist      0.610    accuracy       0.011299   0.112142   \n",
       "13       KNeighborsUnif      0.580    accuracy       0.170330   0.232837   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.001021           1.151814            2       True   \n",
       "1                 0.070311          46.333023            1       True   \n",
       "2                 0.015724           6.151672            1       True   \n",
       "3                 0.018853           5.295700            1       True   \n",
       "4                 0.033105          10.858981            1       True   \n",
       "5                 0.048410           6.276760            1       True   \n",
       "6                 0.077085           4.193133            1       True   \n",
       "7                 0.050142           7.587986            1       True   \n",
       "8                 0.117585           1.386432            1       True   \n",
       "9                 0.100514           2.002491            1       True   \n",
       "10                0.137938           1.526963            1       True   \n",
       "11                0.095917           1.590998            1       True   \n",
       "12                0.011299           0.112142            1       True   \n",
       "13                0.170330           0.232837            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0          14  \n",
       "1           8  \n",
       "2           5  \n",
       "3          11  \n",
       "4          13  \n",
       "5           4  \n",
       "6          12  \n",
       "7           3  \n",
       "8           9  \n",
       "9           6  \n",
       "10         10  \n",
       "11          7  \n",
       "12          2  \n",
       "13          1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call AutoGluon's leaderboard on the trained predictor to output details of all created models \n",
    "first_predictor.leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 7. <a name=\"7\">Model Prediction with AutoGluon</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Now that we trained a model on the train data (that had labels to learn from), let's use the fitted model to predict the labels for the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for the first 20 data points in the test dataset: [2 2 2 2 2 1 2 1 2 2 1 0 2 2 2 1 0 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Call the predict method on the trained predictor to run inference and get predictions on the test dataset\n",
    "prediction = first_predictor.predict(test)\n",
    "\n",
    "# Print a few test predictions\n",
    "print(f\"Predictions for the first 20 data points in the test dataset: {prediction.values[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 8. <a name=\"8\">Re-Train (with full train data) and predict again</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "To improve performance, repeat the process using the full dataset and check whether the score gets better (using AutoGluon leaderboard).\n",
    "\n",
    "__AUTOGLUON FIT OUTPUT__: check that the output refers to the full dataset this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240106_003056\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 600s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240106_003056\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Sep 6 21:15:41 UTC 2023\n",
      "CPU Count:          4\n",
      "Memory Avail:       11.25 GB / 15.32 GB (73.4%)\n",
      "Disk Space Avail:   44.97 GB / 49.04 GB (91.7%)\n",
      "===================================================\n",
      "Train Data Rows:    28305\n",
      "Train Data Columns: 33\n",
      "Label Column:       label\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [1, 2, 0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11568.98 MB\n",
      "\tTrain Data (Original)  Memory Usage: 66.14 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['item_name', 'product_description', 'bullet_point', 'generic_keyword']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 10000\n",
      "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
      "\t\tReducing Vectorizer vocab size from 10000 to 6734 to avoid OOM error\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['marketplace_id']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ID_0']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['ID_0']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 10 | ['number_of_items', 'case_pack_quantity', 'item_package_quantity', 'item_dimensions_height', 'item_dimensions_width', ...]\n",
      "\t\t('int', [])          :  1 | ['ID']\n",
      "\t\t('object', [])       : 16 | ['product_type', 'brand', 'manufacturer', 'part_number', 'model_number', ...]\n",
      "\t\t('object', ['text']) :  4 | ['item_name', 'product_description', 'bullet_point', 'generic_keyword']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   15 | ['product_type', 'brand', 'manufacturer', 'part_number', 'model_number', ...]\n",
      "\t\t('category', ['text_as_category'])  :    4 | ['item_name', 'product_description', 'bullet_point', 'generic_keyword']\n",
      "\t\t('float', [])                       :   10 | ['number_of_items', 'case_pack_quantity', 'item_package_quantity', 'item_dimensions_height', 'item_dimensions_width', ...]\n",
      "\t\t('int', [])                         :    1 | ['ID']\n",
      "\t\t('int', ['binned', 'text_special']) :   98 | ['item_name.char_count', 'item_name.word_count', 'item_name.capital_ratio', 'item_name.lower_ratio', 'item_name.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :    1 | ['list_price_currency']\n",
      "\t\t('int', ['text_ngram'])             : 6564 | ['__nlp__.00', '__nlp__.000', '__nlp__.10', '__nlp__.10 inch', '__nlp__.10 minutes', ...]\n",
      "\t115.0s = Fit runtime\n",
      "\t31 features in original data used to generate 6693 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 360.27 MB (3.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 118.8s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.08832361773538244, Train Rows: 25805, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 481.2s of the 480.71s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 2.487 GB out of 10.920 GB available memory (22.776%)... (20.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.19 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train KNeighborsUnif... Skipping this model.\n",
      "Fitting model: KNeighborsDist ... Training model for up to 475.05s of the 474.56s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 2.487 GB out of 10.921 GB available memory (22.774%)... (20.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.19 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train KNeighborsDist... Skipping this model.\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 468.91s of the 468.42s of remaining time.\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "No improvement since epoch 2: early stopping\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "\t0.822\t = Validation score   (accuracy)\n",
      "\t68.73s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 399.52s of the 399.02s of remaining time.\n",
      "\t0.8692\t = Validation score   (accuracy)\n",
      "\t47.88s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 350.49s of the 350.16s of remaining time.\n",
      "\t0.8684\t = Validation score   (accuracy)\n",
      "\t55.78s\t = Training   runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 293.33s of the 292.62s of remaining time.\n",
      "\t0.828\t = Validation score   (accuracy)\n",
      "\t72.74s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 218.98s of the 218.5s of remaining time.\n",
      "\t0.8256\t = Validation score   (accuracy)\n",
      "\t64.07s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 153.56s of the 153.12s of remaining time.\n",
      "\tMany features detected (6693), dynamically setting 'colsample_bylevel' to 0.14940983116689077 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 217.\n",
      "\t0.8536\t = Validation score   (accuracy)\n",
      "\t155.69s\t = Training   runtime\n",
      "\t0.87s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the -7.7s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT': 0.549, 'LightGBM': 0.183, 'RandomForestEntr': 0.146, 'RandomForestGini': 0.11, 'CatBoost': 0.012}\n",
      "\t0.8724\t = Validation score   (accuracy)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 610.38s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240106_003056\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for the first 20 data points in the test dataset: [2 2 2 2 2 1 2 1 2 2 1 0 2 2 2 1 2 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Retrain the model using all training data \n",
    "# We let AutoGluon handle the train/validation split directly\n",
    "# NOTE: We cap the training time to 10 minutes!\n",
    "second_predictor = TabularPredictor(label=\"label\").fit(\n",
    "    train_data=train, time_limit = 60*10) \n",
    "\n",
    "# Use the trained model to make predictions on the test dataset\n",
    "prediction = second_predictor.predict(test)\n",
    "\n",
    "# Print a few test predictions\n",
    "print(f\"Predictions for the first 20 data points in the test dataset: {prediction.values[0:20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.8724</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>2.899198</td>\n",
       "      <td>396.879091</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.731445</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.8692</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.465028</td>\n",
       "      <td>47.875665</td>\n",
       "      <td>0.465028</td>\n",
       "      <td>47.875665</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.641491</td>\n",
       "      <td>55.776563</td>\n",
       "      <td>0.641491</td>\n",
       "      <td>55.776563</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.8536</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.867544</td>\n",
       "      <td>155.687522</td>\n",
       "      <td>0.867544</td>\n",
       "      <td>155.687522</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.8280</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.471428</td>\n",
       "      <td>72.739019</td>\n",
       "      <td>0.471428</td>\n",
       "      <td>72.739019</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.8256</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.452311</td>\n",
       "      <td>64.068877</td>\n",
       "      <td>0.452311</td>\n",
       "      <td>64.068877</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.8220</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.091722</td>\n",
       "      <td>68.727036</td>\n",
       "      <td>0.091722</td>\n",
       "      <td>68.727036</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_val eval_metric  pred_time_val    fit_time  \\\n",
       "0  WeightedEnsemble_L2     0.8724    accuracy       2.899198  396.879091   \n",
       "1           LightGBMXT     0.8692    accuracy       0.465028   47.875665   \n",
       "2             LightGBM     0.8684    accuracy       0.641491   55.776563   \n",
       "3             CatBoost     0.8536    accuracy       0.867544  155.687522   \n",
       "4     RandomForestGini     0.8280    accuracy       0.471428   72.739019   \n",
       "5     RandomForestEntr     0.8256    accuracy       0.452311   64.068877   \n",
       "6      NeuralNetFastAI     0.8220    accuracy       0.091722   68.727036   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                0.001395           0.731445            2       True   \n",
       "1                0.465028          47.875665            1       True   \n",
       "2                0.641491          55.776563            1       True   \n",
       "3                0.867544         155.687522            1       True   \n",
       "4                0.471428          72.739019            1       True   \n",
       "5                0.452311          64.068877            1       True   \n",
       "6                0.091722          68.727036            1       True   \n",
       "\n",
       "   fit_order  \n",
       "0          7  \n",
       "1          2  \n",
       "2          3  \n",
       "3          6  \n",
       "4          4  \n",
       "5          5  \n",
       "6          1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call AutoGluon's leaderboard on the trained predictor to output details of all created models \n",
    "second_predictor.leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 9. <a name=\"10\">Before You Go</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "After you are done with this Demo, clean model artifacts by uncommenting and executing the cell below.\n",
    "\n",
    "__It is always good practice to clean everything when you are done, preventing the disk from getting full.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm -r AutogluonModels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
